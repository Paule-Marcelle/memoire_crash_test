# -*- coding: utf-8 -*-
"""khi2plusmodels.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dajkMkdNVAbM3HuATYMgSLRpZ6pephMS

### <font color='#00d2d3'> Importer les packages
"""

# Importer les packages
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import re
import nltk
nltk.download('stopwords') # Télécharger le package stopwords
nltk.download('wordnet')
from nltk.corpus import stopwords # Importer le package stopwords

"""### <font color='#00d2d3'> Importer et lire les données"""

# Importer les données
from google.colab import drive
drive.mount('/content/drive')

# Afficher les données
data=pd.read_csv('/content/drive/MyDrive/Future_Intern/reddit_data.csv')
df= pd.read_csv('/content/drive/MyDrive/Memoire/reddit_good.csv')

"""- 1 : Negative
- 0 : Positive
"""

# Dimension des données
df.shape

"""### <font color='#00d2d3'> Pré-traitement des données"""

print(data['selftext'].apply(type).value_counts())
print(df['title'].apply(type).value_counts())

"""#### <font color='#00d2d3'> Pré-traitement des données textuelles"""

# Afficher la première ligne de la colonne text
df['title'][0]

# Afficher la deuxième ligne de la colonne text
data['selftext'][0]

"""###### <font color='#1dd1a1'> Commencer le nettoyage des tweets

"""

# Fonction supprimant les links
def remove_links(title):
    title= re.sub(r'http:?//\S+ | https:?//\S+','',title)
    return title

# Fonction supprimant les @username
def remove_users(title):
    title = re.sub(r'@[\w\-._]+','',title)
    return title

# Supprimer les adresses emails
def email_address(text):
  title= re.sub(r'@[\w\-._]+','',text)
  return title

!pip install contractions

import contractions
# Fonction étendant les contractions
def contraction(title):
    expanded_all = []
    for word in title.split():
        expanded_all.append(contractions.fix(word)) # utiliser la fonction fix de contractions

    expand = ' '.join(expanded_all)
    return expand

# Supprimer html caractères
def clean_html(text):
   title = re.sub(r'&\w+','',text)
   return title

# Remplacer tout ce qui n'est chaines de caractères alphabétiques et espace par ' '
def alpha_b(text):
   title = re.sub(r'^a-zA-Z\s]+',' ',text)
   return title

def crochet(text):
   title= re.sub(r'\[.*?\]', '', text)
   return title

# Fonction remplaçant les espaces multiples et convertissant majuscules en minuscules
def lower(text):
    title = re.sub(r'\s(2,)',' ' ,text)
    return title

# Supprimer les espaces en début et fin de tweet
def clean_space(text):
    title = re.sub(r'^\s|\s$',' ' ,text)
    return title

# Fonction supprimant les stopwords
def remove_stopwords(text):
    Stopwords = stopwords.words('english')
    title= ' '.join([word for word in text.split() if word not in Stopwords])
    return title

# Lemmatization
from nltk.stem import WordNetLemmatizer
lemma=WordNetLemmatizer()
def lem_sw(text):
    title = [lemma.lemmatize(word) for word in text.split()]
    title = " ".join(title)
    return title

"""###### <font color='#1dd1a1'> Appliquer les différentes fonctions sur letitle


"""

# Appliquer la fonction remove_users
data['new_title'] = data.title.apply(func =remove_users)
# Appliquer la fonction remove_links
data['new_title'] = data.new_title.apply(func =remove_links)
# Appliquer la fonction email_address
data['new_title'] = data.new_title.apply(func =email_address)
# Appliquer la fonction remove_contraction
data['new_title'] = data.new_title.apply(func = contraction)
# Appliquer la fonction clean_html
data['new_title'] = data.new_title.apply(func =clean_html)
# Appliquer la fonction alpha_b
data['new_title'] = data.new_title.apply(func =alpha_b)
# Appliquer la fonction crochet
data['new_title'] = data.new_title.apply(func =crochet)
# Appliquer la fonction lower
data['new_title'] = data.new_title.apply(func =lower)
# Appliquer la fonction clean_space
data['new_title'] = data.new_title.apply(func =clean_space)
# Appliquer la fonction remove_stopwords
data['new_title'] = data.new_title.apply(func =remove_stopwords)
# Appliquer la fonction lem_sw
data['new_title'] = data.new_title.apply(func =lem_sw)

# Appliquer la fonction remove_users
df['new_title'] = df.title.apply(func =remove_users)
# Appliquer la fonction remove_links
df['new_title'] = df.new_title.apply(func =remove_links)
# Appliquer la fonction email_address
df['new_title'] = df.new_title.apply(func =email_address)
# Appliquer la fonction remove_contraction
df['new_title'] = df.new_title.apply(func = contraction)
# Appliquer la fonction clean_html
df['new_title'] = df.new_title.apply(func =clean_html)
# Appliquer la fonction alpha_b
df['new_title'] = df.new_title.apply(func =alpha_b)
# Appliquer la fonction crochet
df['new_title'] = df.new_title.apply(func =crochet)
# Appliquer la fonction lower
df['new_title'] = df.new_title.apply(func =lower)
# Appliquer la fonction clean_space
df['new_title'] = df.new_title.apply(func =clean_space)
# Appliquer la fonction remove_stopwords
df['new_title'] = df.new_title.apply(func =remove_stopwords)
# Appliquer la fonction lem_sw
df['new_title'] = df.new_title.apply(func =lem_sw)

# Afficher la ligne d'index 0
df['new_title'][1200]

df.isnull().sum()

df

columns_to_drop = ['title', 'selftext', 'created_utc', 'author', 'subreddit']
# Garder uniquement les colonnes existantes dans le DataFrame
columns_to_drop = [col for col in columns_to_drop if col in data.columns]

data = data.drop(columns=columns_to_drop)
data

columns_to_drop = ['title', 'selftext', 'created_utc', 'author', 'subreddit']
# Garder uniquement les colonnes existantes dans le DataFrame
columns_to_drop = [col for col in columns_to_drop if col in df.columns]

df = df.drop(columns=columns_to_drop)
df

data["label"] = 1  # 1 pour violent
df["label"] = 0  # 0 pour non violent
combined_df = pd.concat([data, df], ignore_index=True)

combined_df

combined_df["label"].value_counts()

from sklearn.utils import resample

# Texte violent (classe minoritaire)
violent = combined_df[combined_df["label"] == 1]

# Texte non violent (classe majoritaire)
non_violent = combined_df[combined_df["label"] == 0]

# Sur-échantillonnage pour équilibrer
non_violent_upsampled = resample(non_violent,
                              replace=True,  # Permet de dupliquer les données existantes
                              n_samples=len(violent),  # Nombre d'échantillons à égaler à la classe majoritaire
                              random_state=42)

# Combiner les deux classes
balanced_df = pd.concat([ violent, non_violent_upsampled])

# Vérifier la répartition des classes
print(balanced_df["label"].value_counts())

balanced_df=combined_df.dropna()

balanced_df.shape

"""### <font color='#00d2d3'> Vectorisation"""



# Importer train_test_split
from sklearn.model_selection import train_test_split

X = balanced_df["new_title"]  # Caractéristiques (textes)
y = balanced_df["label"]  # Labels (0 ou 1)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"Taille des données d'entraînement : {len(X_train)}")
print(f"Taille des données de test : {len(X_test)}")

from sklearn.feature_extraction.text import TfidfVectorizer

# Initialiser le vectoriseur TF-IDF
vectorizer = TfidfVectorizer(max_features=5000)  # Ajuste max_features si besoin

# Transformer les données
X_train_vec = vectorizer.fit_transform(X_train).toarray()
X_test_vec = vectorizer.transform(X_test).toarray()

print(f"Taille des vecteurs TF-IDF (entraînement) : {X_train_vec.shape}")
print(f"Taille des vecteurs TF-IDF (test) : {X_test_vec.shape}")

from sklearn.feature_selection import chi2
import numpy as np

# Appliquer le test du Chi-2
chi2_scores, p_values = chi2(X_train_vec, y_train)

# Associer les scores aux termes
features = vectorizer.get_feature_names_out()
chi2_results = pd.DataFrame({
    "Feature": features,
    "Chi2_Score": chi2_scores,
    "P_Value": p_values
})

# Trier par pertinence
chi2_results = chi2_results.sort_values(by="Chi2_Score", ascending=False)

# Afficher les termes les plus pertinents
print("Les termes les plus pertinents selon le Chi-2 :")
print(chi2_results.head(10))

# Filtrer les termes pertinents
relevant_features = chi2_results[chi2_results["P_Value"] < 0.05]

print(f"Nombre de termes pertinents sélectionnés : {len(relevant_features)}")
print(relevant_features.head())

# Créer un nouveau vecteur TF-IDF avec les termes pertinents
selected_features = relevant_features["Feature"].tolist()

# Reconstruire le vectoriseur avec les termes sélectionnés
vectorizer_selected = TfidfVectorizer(vocabulary=selected_features)

# Transformer les données d'entraînement et de test avec les termes sélectionnés
X_train_selected = vectorizer_selected.fit_transform(X_train)
X_test_selected = vectorizer_selected.transform(X_test)

print(f"Taille de la nouvelle matrice d'entraînement : {X_train_selected.shape}")
print(f"Taille de la nouvelle matrice de test : {X_test_selected.shape}")



# # Sauvegarder le vectoriseur
# import joblib
# joblib.dump(vectorizer_selected, "vectorizer_selected.pkl")  # Si tu utilises le test Chi-2
# joblib.dump(model_lr, "logistic_regression_model.pkl")



"""#LOGISTIC REGRESSION"""

from sklearn.linear_model import LogisticRegression

# Initialiser le modèle
model_lr = LogisticRegression(random_state=42)

# Entraîner le modèle
model_lr.fit(X_train_selected, y_train)

print("Modèle entraîné avec succès !")

from sklearn.metrics import classification_report, accuracy_score

# Faire des prédictions
y_pred = model_lr.predict(X_test_selected)

# Afficher les métriques
print("Rapport de classification :")
print(classification_report(y_test, y_pred))

# Précision globale
accuracy = accuracy_score(y_test, y_pred)
print(f"Précision du modèle : {accuracy:.2f}")

# Sauvegarder le vectoriseur
import joblib
joblib.dump(vectorizer_selected, "vectorizer_selected.pkl")  # Si tu utilises le test Chi-2
joblib.dump(model_lr, "logistic_regression_model.pkl")

vectorizer_selected = joblib.load("vectorizer_selected.pkl")
model_lr = joblib.load("logistic_regression_model.pkl")

# Exemple de prédictions personnalisées
new_texts = [
    "Feel like she is emotionally abuse.",
    "Life is great those days",
    "I am happy",
    "I am in a safe relationship",
    "My dad used to beat me after school",# Exemple violent
        # Exemple non violent
]

# Transformer les nouveaux textes
new_texts_vec =  vectorizer_selected.transform(new_texts)

# Faire des prédictions
predictions = model_lr.predict(new_texts_vec)

# Afficher les résultats
for text, pred in zip(new_texts, predictions):
    label = "Potential danger" if pred == 1 else "No danger"
    print(f"Texte : '{text}' -> Prédiction : {label}")

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Prédire sur les données de test
y_pred = model_lr.predict(X_test_selected)  # Si tu utilises un modèle LSTM ou un autre modèle
if hasattr(y_pred[0], "__len__"):  # Si le modèle donne des probabilités
    y_pred = (y_pred > 0.5).astype(int)  # Convertir les probabilités en classes binaires

# Calculer la matrice de confusion
cm = confusion_matrix(y_test, y_pred)

# Afficher la matrice de confusion
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["No danger", "Potential danger"])
disp.plot(cmap=plt.cm.Blues)
plt.title("Matrice de confusion")
plt.show()

"""SVM"""

# Charger les données équilibrées
# X = balanced_df["new_title"]  # Caractéristiques (textes)
# y = balanced_df["label"]  # Labels (0 ou 1)

# # Diviser les données en jeux d'entraînement et de test
# from sklearn.model_selection import train_test_split
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# # Convertir les textes en vecteurs numériques avec TF-IDF
# from sklearn.feature_extraction.text import TfidfVectorizer
# vectorizer = TfidfVectorizer(max_features=5000)
# X_train_vec = vectorizer.fit_transform(X_train).toarray()
# X_test_vec = vectorizer.transform(X_test).toarray()

from sklearn.svm import SVC
from sklearn.metrics import classification_report, accuracy_score

# Initialiser le modèle SVM
model_svm = SVC(kernel='linear', random_state=42)

# Entraîner le modèle
model_svm.fit(X_train_selected, y_train)

print("SVM entraîné avec succès !")

# Faire des prédictions
y_pred = model_svm.predict(X_test_selected)

# Afficher les métriques
print("Rapport de classification :")
print(classification_report(y_test, y_pred))

# Précision globale
accuracy = accuracy_score(y_test, y_pred)
print(f"Précision du modèle : {accuracy:.2f}")

# Exemple pour un SVM
joblib.dump(model_svm, "svm_model.pkl")

# Exemple de textes à prédire
new_texts = [
    "Feel like she is emotionally abuse.",
    "Life is great those days",
    "I am happy",
    "I am in a safe relationship",
    "My dad used to beat me after school",# Exemple violent
        # Exemple non violent
]

# Transformer les textes
new_texts_vec =  vectorizer_selected.transform(new_texts)

# Prédire avec le modèle
predictions = model_svm.predict(new_texts_vec)

# Afficher les résultats
for text, pred in zip(new_texts, predictions):
    label = "Potential danger" if pred == 1 else "No danger"
    print(f"Texte : '{text}' -> Prédiction : {label}")

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Prédire sur les données de test
y_pred = model_svm.predict(X_test_selected)  # Si tu utilises un modèle LSTM ou un autre modèle
if hasattr(y_pred[0], "__len__"):  # Si le modèle donne des probabilités
    y_pred = (y_pred > 0.5).astype(int)  # Convertir les probabilités en classes binaires

# Calculer la matrice de confusion
cm = confusion_matrix(y_test, y_pred)

# Afficher la matrice de confusion
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["No danger", "Potential danger"])
disp.plot(cmap=plt.cm.Reds)
plt.title("Matrice de confusion")
plt.show()

"""RANDOM FOREST"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score

# Initialiser le modèle Random Forest
model_rf = RandomForestClassifier(n_estimators=100, random_state=42)

# Entraîner le modèle
model_rf.fit(X_train_selected, y_train)

print("Random Forest entraîné avec succès !")

# Faire des prédictions
y_pred = model_rf.predict(X_test_selected)

# Afficher les métriques
print("Rapport de classification :")
print(classification_report(y_test, y_pred))

# Précision globale
accuracy = accuracy_score(y_test, y_pred)
print(f"Précision du modèle : {accuracy:.2f}")

# Exemple pour un SVM
joblib.dump(model_rf, "svm_model.pkl")

# Exemple de textes à prédire
new_texts = [
    "Feel like she is emotionally abuse.",
    "Life is great those days",
    "I am happy",
    "I am in a safe relationship",
    "My dad used to beat me after school",# Exemple violent
        # Exemple non violent
]

# Transformer les nouveaux textes
new_texts_vec =  vectorizer_selected.transform(new_texts)

# Faire des prédictions
predictions = model_rf.predict(new_texts_vec)

# Afficher les résultats
for text, pred in zip(new_texts, predictions):
    label = "Potiental danger" if pred == 1 else "No danger"
    print(f"Texte : '{text}' -> Prédiction : {label}")

#fin

"""XGBOOST"""

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Prédire sur les données de test
y_pred = model_rf.predict(X_test_selected)  # Si tu utilises un modèle LSTM ou un autre modèle
if hasattr(y_pred[0], "__len__"):  # Si le modèle donne des probabilités
    y_pred = (y_pred > 0.5).astype(int)  # Convertir les probabilités en classes binaires

# Calculer la matrice de confusion
cm = confusion_matrix(y_test, y_pred)

# Afficher la matrice de confusion
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["No danger", "Potential danger"])
disp.plot(cmap=plt.cm.BuGn)
plt.title("Matrice de confusion")
plt.show()

pip install xgboost

from xgboost import XGBClassifier
from sklearn.metrics import classification_report, accuracy_score

# Initialiser le modèle XGBoost
model_xgb = XGBClassifier(use_label_encoder=False, eval_metric="logloss", random_state=42)

# Entraîner le modèle
model_xgb.fit(X_train_selected, y_train)

print("XGBoost entraîné avec succès !")

# Faire des prédictions
y_pred = model_xgb.predict(X_test_selected)

# Afficher les métriques
print("Rapport de classification :")
print(classification_report(y_test, y_pred))

# Précision globale
accuracy = accuracy_score(y_test, y_pred)
print(f"Précision du modèle : {accuracy:.2f}")

joblib.dump(model_xgb, "Xgboost_model.pkl")
# Exemple de textes à prédire
new_texts = [
    "Feel like she is emotionally abuse.",
    "Life is great those days",
    "I am happy",
    "I am in a safe relationship",
    "My dad used to beat me after school",# Exemple violent
        # Exemple non violent
]

# Transformer les nouveaux textes
new_texts_vec =  vectorizer_selected.transform(new_texts)

# Faire des prédictions
predictions = model_xgb.predict(new_texts_vec)

# Afficher les résultats
for text, pred in zip(new_texts, predictions):
    label = "Potential danger" if pred == 1 else "No danger"
    print(f"Texte : '{text}' -> Prédiction : {label}")

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Prédire sur les données de test
y_pred = model_xgb.predict(X_test_selected)  # Si tu utilises un modèle LSTM ou un autre modèle
if hasattr(y_pred[0], "__len__"):  # Si le modèle donne des probabilités
    y_pred = (y_pred > 0.5).astype(int)  # Convertir les probabilités en classes binaires

# Calculer la matrice de confusion
cm = confusion_matrix(y_test, y_pred)

# Afficher la matrice de confusion
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["No danger", "Potential danger"])
disp.plot(cmap=plt.cm.BuPu)
plt.title("Matrice de confusion")
plt.show()

"""KNN"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, accuracy_score

# Initialiser le modèle KNN
model_knn = KNeighborsClassifier(n_neighbors=5, metric='cosine')  # n_neighbors = 5 est un bon point de départ

# Entraîner le modèle
model_knn.fit(X_train_selected, y_train)

print("KNN entraîné avec succès !")

# Faire des prédictions
y_pred = model_knn.predict(X_test_selected)

# Afficher les métriques
print("Rapport de classification :")
print(classification_report(y_test, y_pred))

# Précision globale
accuracy = accuracy_score(y_test, y_pred)
print(f"Précision du modèle : {accuracy:.2f}")

# Exemple de textes à prédire
new_texts = [
    "I see diomestic violence everday.",
    "Is it good to be beaten ",# Exemple violent
    "She enjoys spending time with friends",
    "Feel like she is emotionally abuse.",
    "Life is great those days",
    "I am happy",
    "I am in a safe relationship",
    "My dad used to beat me after school",# Exemple non violent
]

# Transformer les nouveaux textes
new_texts_vec = vectorizer_selected.transform(new_texts)

# Faire des prédictions
predictions = model_knn.predict(new_texts_vec)

# Afficher les résultats
for text, pred in zip(new_texts, predictions):
    label = "Potential danger" if pred == 1 else "No danger"
    print(f"Texte : '{text}' -> Prédiction : {label}")

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Prédire sur les données de test
y_pred = model_knn.predict(X_test_selected)  # Si tu utilises un modèle LSTM ou un autre modèle
if hasattr(y_pred[0], "__len__"):  # Si le modèle donne des probabilités
    y_pred = (y_pred > 0.5).astype(int)  # Convertir les probabilités en classes binaires

# Calculer la matrice de confusion
cm = confusion_matrix(y_test, y_pred)

# Afficher la matrice de confusion
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["No danger", "Potential danger"])
disp.plot(cmap=plt.cm.gist_gray)
plt.title("Matrice de confusion")
plt.show()

"""#DECISION TREE"""

from sklearn.tree import DecisionTreeClassifier
# Initialiser le modèle Decision Tree
model_dt = DecisionTreeClassifier(random_state=42)

# Entraîner le modèle
model_dt.fit(X_train_selected, y_train)

print("Modèle Decision Tree entraîné avec succès !")

# Faire des prédictions
y_pred = model_dt.predict(X_test_selected)

# Afficher les métriques
print("Rapport de classification :")
print(classification_report(y_test, y_pred))
# Précision globale
accuracy = accuracy_score(y_test, y_pred)
print(f"Précision du modèle : {accuracy:.2f}")

# Exemple de textes à prédire
new_texts = [
    "I see diomestic violence everday.",
    "Is it good to be beaten ",# Exemple violent
    "She enjoys spending time with friends",
    "Feel like she is emotionally abuse.",
    "Life is great those days",
    "I am happy",
    "I am in a safe relationship",
    "My dad used to beat me after school",# Exemple non violent
]

# Transformer les nouveaux textes
new_texts_vec = vectorizer_selected.transform(new_texts)

# Faire des prédictions
predictions = model_dt.predict(new_texts_vec)

# Afficher les résultats
for text, pred in zip(new_texts, predictions):
    label = "Potential danger" if pred == 1 else "No danger"
    print(f"Texte : '{text}' -> Prédiction : {label}")

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Prédire sur les données de test
y_pred = model_dt.predict(X_test_selected)  # Si tu utilises un modèle LSTM ou un autre modèle
if hasattr(y_pred[0], "__len__"):  # Si le modèle donne des probabilités
    y_pred = (y_pred > 0.5).astype(int)  # Convertir les probabilités en classes binaires

# Calculer la matrice de confusion
cm = confusion_matrix(y_test, y_pred)

# Afficher la matrice de confusion
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["No danger", "Potential danger"])
disp.plot(cmap=plt.cm.gnuplot)
plt.title("Matrice de confusion")
plt.show()

"""#MLP"""

from sklearn.neural_network import MLPClassifier

# Initialiser le modèle Perceptron Multicouche
model_mlp = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=300, random_state=42)

# Entraîner le modèle
model_mlp.fit(X_train_selected, y_train)
print("Modèle MLP (Perceptron Multicouche) entraîné avec succès !")

# Faire des prédictions
y_pred = model_mlp.predict(X_test_selected)

# Afficher les métriques
print("Rapport de classification :")
print(classification_report(y_test, y_pred))

# Précision globale
accuracy = accuracy_score(y_test, y_pred)
print(f"Précision du modèle : {accuracy:.2f}")

# Exemple de textes à prédire
new_texts = [
    "I see diomestic violence everday.",
    "Is it good to be beaten ",# Exemple violent
    "She enjoys spending time with friends",
    "Feel like she is emotionally abuse.",
    "Life is great those days",
    "I am happy",
    "I am in a safe relationship",
    "My dad used to beat me after school",# Exemple non violent
]

# Transformer les nouveaux textes
new_texts_vec = vectorizer_selected.transform(new_texts)

# Faire des prédictions
predictions = model_mlp.predict(new_texts_vec)

# Afficher les résultats
for text, pred in zip(new_texts, predictions):
    label = "Potential danger" if pred == 1 else "No danger"
    print(f"Texte : '{text}' -> Prédiction : {label}")

# Prédire sur les données de test
y_pred = model_mlp.predict(X_test_selected)  # Si tu utilises un modèle LSTM ou un autre modèle
if hasattr(y_pred[0], "__len__"):  # Si le modèle donne des probabilités
    y_pred = (y_pred > 0.5).astype(int)  # Convertir les probabilités en classes binaires

# Calculer la matrice de confusion
cm = confusion_matrix(y_test, y_pred)

# Afficher la matrice de confusion
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["No danger", "Potential danger"])
disp.plot(cmap=plt.cm.Reds)
plt.title("Matrice de confusion")
plt.show()

"""LSTM"""

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split

# Charger les textes et labels
X = balanced_df["new_title"].tolist()
y = balanced_df["label"].tolist()

# Tokeniser les textes
tokenizer = Tokenizer(num_words=5000, oov_token="<OOV>")
tokenizer.fit_on_texts(X)

# Convertir les textes en séquences
X_sequences = tokenizer.texts_to_sequences(X)

# Padding pour obtenir des séquences de même longueur
X_padded = pad_sequences(X_sequences, maxlen=100, padding='post', truncating='post')

# Diviser les données en ensembles d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.2, random_state=42)

import numpy as np

# Convertir les labels en tableaux Numpy
y_train = np.array(y_train)
y_test = np.array(y_test)


print(f"Taille des données d'entraînement : {len(X_train)}")
print(f"Taille des données de test : {len(X_test)}")

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout

# Définir le modèle
model_lstm = Sequential([
    Embedding(input_dim=5000, output_dim=64, input_length=100),  # Couche d'embedding
    LSTM(64, return_sequences=False),  # LSTM avec 64 unités
    Dropout(0.5),  # Dropout pour éviter le sur-ajustement
    Dense(64, activation='relu'),  # Couche entièrement connectée
    Dense(1, activation='sigmoid')  # Couche de sortie
])

# Compiler le modèle
model_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

print(model_lstm.summary())

# Entraîner le modèle
history = model_lstm.fit(
    X_train, y_train,
    validation_data=(X_test, y_test),
    epochs=5,
    batch_size=32
)

# Évaluer le modèle
loss, accuracy = model_lstm.evaluate(X_test, y_test)
print(f"Précision : {accuracy:.2f}")

# Nouveaux textes
new_texts = [
    "Feel like she is emotionally abuse.",
    "Life is great those days",
    "I am happy",
    "I am in a safe relationship",
    "My dad used to beat me after school",# Exemple violent
        # Exemple non violent
]

# Prétraiter les nouveaux textes
new_sequences = tokenizer.texts_to_sequences(new_texts)
new_padded = pad_sequences(new_sequences, maxlen=100, padding='post', truncating='post')

# Faire des prédictions
predictions = model_lstm.predict(new_padded)

# Afficher les résultats
for text, pred in zip(new_texts, predictions):
    label = "Violent" if pred > 0.5 else "Non violent"
    print(f"Texte : '{text}' -> Prédiction : {label}")

# fin

"""BERT"""

pip install transformers torch

from transformers import BertTokenizer
from sklearn.model_selection import train_test_split
import torch

# Charger les données équilibrées
X = balanced_df["new_title"].tolist()
y = balanced_df["label"].tolist()

# Diviser en ensembles d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Charger le tokenizer de BERT
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

# Tokeniser les textes
def tokenize_texts(texts, labels, max_length=128):
    inputs = tokenizer(texts, padding=True, truncation=True, max_length=max_length, return_tensors="pt")
    labels = torch.tensor(labels)
    return inputs, labels

train_inputs, train_labels = tokenize_texts(X_train, y_train)
test_inputs, test_labels = tokenize_texts(X_test, y_test)

from transformers import BertForSequenceClassification

# Charger le modèle BERT pour une tâche de classification binaire
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)

from torch.utils.data import DataLoader, TensorDataset
from transformers import AdamW

# Préparer les datasets pour DataLoader
train_dataset = TensorDataset(train_inputs['input_ids'], train_inputs['attention_mask'], train_labels)
test_dataset = TensorDataset(test_inputs['input_ids'], test_inputs['attention_mask'], test_labels)

# Créer les DataLoaders
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=16)

# Optimiseur
optimizer = AdamW(model.parameters(), lr=5e-5)

# Déplacer le modèle sur GPU si disponible
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

from torch.nn import CrossEntropyLoss

# Fonction d'entraînement
def train(model, train_loader, optimizer, device):
    model.train()
    total_loss = 0
    for batch in train_loader:
        input_ids, attention_mask, labels = [b.to(device) for b in batch]

        # Réinitialiser les gradients
        optimizer.zero_grad()

        # Faire une passe avant
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        total_loss += loss.item()

        # Rétropropagation
        loss.backward()
        optimizer.step()

    return total_loss / len(train_loader)

# Boucle d'entraînement
epochs = 10
for epoch in range(epochs):
    train_loss = train(model, train_loader, optimizer, device)
    print(f"Epoch {epoch+1}/{epochs}, Loss: {train_loss:.4f}")

from sklearn.metrics import classification_report

def evaluate(model, test_loader, device):
    model.eval()
    preds, true_labels = [], []
    with torch.no_grad():
        for batch in test_loader:
            input_ids, attention_mask, labels = [b.to(device) for b in batch]
            outputs = model(input_ids, attention_mask=attention_mask)
            logits = outputs.logits
            preds.extend(torch.argmax(logits, axis=1).cpu().numpy())
            true_labels.extend(labels.cpu().numpy())
    return preds, true_labels

# Faire l'évaluation
predictions, true_labels = evaluate(model, test_loader, device)

# Afficher le rapport de classification
print("Rapport de classification :")
print(classification_report(true_labels, predictions))

# Nouveaux textes
new_texts = [
    "I see diomestic violence everday.",
    "Is it good to be beaten ",# Exemple violent
    "She enjoys spending time with friends",
    "Feel like she is emotionally abuse.",
    "Life is great those days",
    "I am happy",
    "I am in a safe relationship",
    "My dad used to beat me after school",# Exemple non violent
]

# Tokeniser les nouveaux textes
new_inputs = tokenizer(new_texts, padding=True, truncation=True, max_length=128, return_tensors="pt")
new_inputs = {key: value.to(device) for key, value in new_inputs.items()}

# Faire des prédictions
model.eval()
with torch.no_grad():
    outputs = model(**new_inputs)
    predictions = torch.argmax(outputs.logits, axis=1)

# Afficher les résultats
for text, pred in zip(new_texts, predictions.cpu().numpy()):
    label = "Violent" if pred == 1 else "Non violent"
    print(f"Texte : '{text}' -> Prédiction : {label}")